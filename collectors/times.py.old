#!/usr/bin/env python3.5
import os
import json
import shutil
import subprocess
import statistics
import pandas as pd
import itertools
from collections import defaultdict

_similarity_dict  = defaultdict(dict)
_ttfb_dict  = defaultdict(dict)
def tcp_pkt():
    if filename.endswith('.tcptrace'):
        data_array = pd.read_csv(os.path.join(root, filename), skiprows=8, )
        host_b = data_array['host_b'].values
        port_b = data_array['port_b'].values
        totoal_packet_b2a = data_array['total_packets_b2a'].values
        for index, my_server in enumerate(host_b):
            conn_dict.setdefault(str(my_server) + str(int(port_b[index])), []).append(totoal_packet_b2a[index])
            run_no_list[run_no] = conn_dict
    return run_no_list
 
_experiment_dir = '/home/jnejati/PLTSpeed/desktop_b5d100-mo'
for _site_dir in os.listdir(_experiment_dir):
    _similarity_run_dict = {}
    _ttfb_run_dict = {}
    _load_list = []
    _ttfb_list = []
    _site_dir = os.path.join(_experiment_dir, _site_dir)
    _runs = [x for x in os.listdir(_site_dir) if x.startswith('run')]
    _similarity_list = []
    _similarity_dict = {}
    conn_dict = {}
    run_no_list = [0] * 100
    with open(os.path.join(_site_dir, 'pairwise_normalized.txt')) as _s:
         for line in _s:
             _sim_index = line.split()[2]
             _run1 = line.split()[0]
             _run1 = line.split()[1]
             _similarity_run_dict[_run1 + _run2] =  float(_sim_index)
         #_similarity_dict[_site_dir] = str(statistics.median(_similarity_list))
         _similarity_dict[_site_dir] =_similarity_run_dict
    for _run_no in _runs:
        _run_dir = os.path.join(_site_dir, _run_no)
        _analysis_dir = os.path.join(_run_dir, 'analysis')
        _tcptrace_dir = os.path.join(_run_dir, 'tcptrace')
        for _file in os.listdir(_analysis_dir):
            analysis_file = os.path.join(_analysis_dir, _file)
            with open(analysis_file) as _f:
                _data = json.load(_f)
                _load_list.append((_data[0]['load']))
                _ttfb_run_dict[_run_no] = _data[1]['objs'][0][1]['responseReceivedTime']
         
        """for _tfile in os.listdir(_tcptrace_dir):
            tcptrace_file = os.path.join(_tcptrace_dir, _tfile)
            data_array = pd.read_csv(tcptrace_file, skiprows=8, )
            host_b = data_array['host_b'].values
            port_b = data_array['port_b'].values
            totoal_packet_b2a = data_array['total_packets_b2a'].values
            conn_dict = {}
            for index, my_server in enumerate(host_b):
                if not int(port_b[index]) == 9222:
                    conn_dict.setdefault(str(my_server) + str(int(port_b[index])), []).append(totoal_packet_b2a[index])
                run_no_list[int(_run_no.split('_')[1])] = conn_dict
        #print(len(conn_dict['www.microsoft.com443']))"""
    for _site_dir in os.listdir(_experiment_dir):
        _site_dir = os.path.join(_experiment_dir, _site_dir)
        _runs = [x for x in os.listdir(_site_dir) if x.startswith('run')]
        _runs_combinations = [ x for x in (itertools.combinations(_runs, 2)) if x[0] != x[1]]
        for _run_no_pair in _runs_combinations:
            _ttfb_run_dict[''.join(list(_run_no_pair))] = [_ttfb_run_dict[_run_no_pair[0]], _ttfb_run_dict[_run_no_pair[1]]]
        _ttfb_dict[_site_dir] = _ttfb_run_dict
    for _site, _run_ttfb_pair  in _ttfb_dict.items(): 
        for _runs, _ttfb in _run_ttfb_pair.items():
            print(_runs + ' ' + _ttfb + ' ' + str(similarity_dict[_site][_runs])

    """print(100*'-')
    print('Stats for: ' + _site_dir )
    print('Load Median: ' + str(round(statistics.median(_load_list), 2)))
    print('Load Stdev: ' + str(round(statistics.stdev(_load_list), 2)))
    print('TTFB Median: ' + str(round(statistics.median(_ttfb_list), 2)))
    print('TTFB Stdev: ' + str(round(statistics.stdev(_ttfb_list), 2)))
    print('Similarity Median: ' + str(_similarity_dict[_site_dir]))"""
